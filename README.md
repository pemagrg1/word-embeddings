# word-embeddings
Embedding is the process of converting a word or a piece of text to a continuos vector space of real number, usually in low dimension.

In this repository, we have used Gensim's Word2Vec, fastText, GloVe.a

#### Gensim
Gensim is an open-source library for unsupervised topic modeling and natural language processing, using modern statistical machine learning. Gensim is implemented in Python and Cython.


#### GloVe
GloVe, coined from Global Vectors, is a model for distributed word representation. The model is an unsupervised learning algorithm for obtaining vector representations for words. This is achieved by mapping words into a meaningful space where the distance between words is related to semantic similarity.


#### fastText
fastText is a library for learning of word embeddings and text classification created by Facebook's AI Research lab. The model allows to create an unsupervised learning or supervised learning algorithm for obtaining vector representations for words.
